import whisper
import numpy as np
import sounddevice as sd
import logging
import time
from typing import Tuple, Optional, Dict, Union
import warnings
import torch

class SpeechRecognizer:
    """
    éŸ³å£°èªè­˜ï¼ˆSTTï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®å¤‰æ›æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸSTTæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚
    """
    
    def __init__(self, config=None):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.logger = logging.getLogger(__name__)
        self.config = config
        
        # è­¦å‘Šã®æŠ‘åˆ¶
        self._suppress_warnings()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self.model_size = "base"
        self.sample_rate = 16000
        self.max_duration = 30
        self.language = "ja"
        self.device = "cpu"
        
        # è¨­å®šã‹ã‚‰å€¤ã‚’å–å¾—
        if config:
            self.model_size = config.get("stt", "model", self.model_size)
            self.sample_rate = config.get("audio", "sample_rate", self.sample_rate)
            self.max_duration = config.get("audio", "max_duration", self.max_duration)
            self.language = config.get("stt", "language", self.language)
            self.device = config.get("stt", "device", self.device)
        
        # ãƒ¢ãƒ‡ãƒ«ã®é…å»¶ãƒ­ãƒ¼ãƒ‰
        self._model = None
        
    def _suppress_warnings(self):
        """è­¦å‘Šã¨ãƒ­ã‚°ã®æŠ‘åˆ¶"""
        # Whisperã®è­¦å‘Šã‚’æŠ‘åˆ¶
        logging.getLogger("whisper").setLevel(logging.ERROR)
        warnings.filterwarnings("ignore", category=UserWarning)
        warnings.filterwarnings("ignore", category=FutureWarning)
        
        # PyTorchã®è­¦å‘Šã‚’æŠ‘åˆ¶
        logging.getLogger("torch").setLevel(logging.ERROR)
        torch.set_warn_always(False)
        
    def load_model(self) -> bool:
        """
        Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
        
        Returns:
            bool: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if self._model is not None:
            return True
            
        try:
            self.logger.info(f"Whisperãƒ¢ãƒ‡ãƒ« ({self.model_size}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            start_time = time.time()
            self._model = whisper.load_model(self.model_size, device=self.device)
            load_time = time.time() - start_time
            self.logger.info(f"Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ (æ‰€è¦æ™‚é–“: {load_time:.2f}ç§’)")
            return True
        except Exception as e:
            self.logger.error(f"Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
            return False
    
    def record_audio(self, max_duration=None, silence_threshold=0.01, silence_time=2.0) -> Optional[np.ndarray]:
        """
        ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹
        
        Args:
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰ã€Noneã®å ´åˆã¯è¨­å®šå€¤ã‚’ä½¿ç”¨
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
            silence_time: ç„¡éŸ³åˆ¤å®šã™ã‚‹æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            np.ndarray: éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã€å¤±æ•—æ™‚ã¯None
        """
        if max_duration is None:
            max_duration = self.max_duration
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰silence_thresholdã‚’å–å¾—ï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ï¼‰
        config_threshold = self.config.get("audio", "silence_threshold", None)
        if config_threshold is not None:
            silence_threshold = float(config_threshold)
            self.logger.debug(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–¾å€¤ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: silence_threshold={silence_threshold}")
            
        try:
            self.logger.info("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã™...")
            audio_chunks = []
            
            # ç„¡éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ã‚¦ãƒ³ãƒˆç”¨
            silent_frames = 0
            chunk_duration = 0.1  # 1ãƒãƒ£ãƒ³ã‚¯å½“ãŸã‚Šã®ç§’æ•°
            required_silent_frames = int(silence_time / chunk_duration)  # ç„¡éŸ³åˆ¤å®šã«å¿…è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            
            stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=1,
                dtype=np.float32,
                blocksize=int(self.sample_rate * chunk_duration)  # 0.1ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
            )
            
            with stream:
                start_time = time.time()
                self.logger.debug("éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸ") 
                
                has_detected_voice = False  # æœ‰å£°æ¤œå‡ºãƒ•ãƒ©ã‚°
                
                while True:
                    audio_chunk, _ = stream.read(int(self.sample_rate * chunk_duration))
                    audio_chunks.append(audio_chunk)
                    
                    # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                    current_level = np.max(np.abs(audio_chunk))
                    if current_level < silence_threshold:
                        silent_frames += 1
                        if silent_frames >= required_silent_frames:
                            if has_detected_voice:  # æœ‰å£°ã‚’æ¤œå‡ºã—ãŸå¾Œã®ç„¡éŸ³ã®ã¿çµ‚äº†æ¡ä»¶ã¨ã™ã‚‹
                                self.logger.debug(f"ç„¡éŸ³ã‚’ {silence_time}ç§’ æ¤œå‡ºã—ãŸãŸã‚éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã™")
                                break
                    else:
                        # éŸ³å£°ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
                        if not has_detected_voice and current_level >= silence_threshold * 2:  # ã‚ˆã‚Šå¼·ã„éŸ³å£°ã®å ´åˆã¯æœ‰å£°ã¨åˆ¤å®š
                            has_detected_voice = True
                            self.logger.debug(f"æœ‰å£°ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼ˆãƒ¬ãƒ™ãƒ«: {current_level:.4f}ï¼‰")
                        
                        # ç„¡éŸ³ã‚«ã‚¦ãƒ³ãƒˆã®ãƒªã‚»ãƒƒãƒˆ
                        silent_frames = 0
                        
                    # æœ€å¤§éŒ²éŸ³æ™‚é–“ã®ãƒã‚§ãƒƒã‚¯
                    elapsed_time = time.time() - start_time
                    if elapsed_time >= max_duration:
                        self.logger.debug(f"æœ€å¤§éŒ²éŸ³æ™‚é–“ {max_duration}ç§’ ã«é”ã—ãŸãŸã‚éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã™")
                        break
            
            if not audio_chunks:
                self.logger.warning("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return None
                
            audio = np.concatenate(audio_chunks)
            recording_length = len(audio) / self.sample_rate
            self.logger.info(f"âœ… éŸ³å£°å…¥åŠ›å®Œäº†ï¼ˆé•·ã•: {recording_length:.1f}ç§’ï¼‰")
            
            # ãƒãƒ¼ãƒãƒ©ã‚¤ã‚º
            if np.max(np.abs(audio)) > 0:
                audio = audio / np.max(np.abs(audio))
                
            return audio.reshape(1, -1)
                
        except Exception as e:
            self.logger.error(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def transcribe_file(self, audio_file: str) -> Optional[str]:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
        
        Args:
            audio_file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            str: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if not self.load_model():
                return None
                
            self.logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {audio_file}")
            
            result = self._model.transcribe(
                audio_file,
                language=self.language,
                fp16=False
            )
            
            recognized_text = result["text"].strip()
            self.logger.info(f"âœ… éŸ³å£°èªè­˜çµæœ: {recognized_text}")
            return recognized_text
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def transcribe(self, audio: np.ndarray) -> Optional[str]:
        """
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
        
        Args:
            audio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆnumpyé…åˆ—ï¼‰
            
        Returns:
            str: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if not self.load_model():
                return None
                
            self.logger.info("ğŸ”„ éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œä¸­...")
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚’èª¿æ•´
            audio_data = audio.squeeze()
            
            # éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
            result = self._model.transcribe(
                audio_data,
                language=self.language,
                fp16=False
            )
            
            recognized_text = result["text"].strip()
            self.logger.info(f"âœ… éŸ³å£°èªè­˜çµæœ: {recognized_text}")
            return recognized_text
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def transcribe_with_timestamps(self, audio: Union[np.ndarray, str]) -> Optional[Dict]:
        """
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨æ™‚é–“æƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Args:
            audio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆnumpyé…åˆ—ï¼‰ã¾ãŸã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            Dict: èªè­˜çµæœï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ï¼‰ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            if not self.load_model():
                return None
                
            self.logger.info("ğŸ”„ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãéŸ³å£°èªè­˜ã‚’å®Ÿè¡Œä¸­...")
            
            # éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
            result = self._model.transcribe(
                audio,
                language=self.language,
                word_timestamps=True,
                fp16=False
            )
            
            self.logger.info(f"âœ… ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãéŸ³å£°èªè­˜å®Œäº†: {len(result['segments'])}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            return result
            
        except Exception as e:
            self.logger.error(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_available_models(self) -> list:
        """
        åˆ©ç”¨å¯èƒ½ãªWhisperãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’è¿”ã™
        
        Returns:
            list: ãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
        """
        return ["tiny", "base", "small", "medium", "large"] 